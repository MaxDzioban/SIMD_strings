# Робота із стрічками за допомогою SIMD (AVX2)
--- 
Команда: Дзьобан Максим, Биков Данило, Шевчук Іван

В цій лабораторній роботі ми переробили звичайну реалізацію стрічки, що використовує стандартні інструменти с++ на реалізацію, що використовує SIMD інструкції
(в контексті цього звіту це AVX2) та дослідили швидкодію SIMD реалізації порівняно зі звичайною. Перероблену стрічку можна побачити в файлах mystring_avx.cpp та mystring_avx.h.

Для досягнення цілей було замінено послідовні цикли копіювання (for, memcpy) на SIMD-команди:

- _mm256_loadu_si256 -- завантажує цілочисельні значення з 256-бітної незгрупованої (unaligned) області памʼяті, на яку вказує *a, у вектор цілих чисел, який повертається інструкцією.

- _mm256_storeu_si256 -- виконує операцію збереження, переміщаючи цілочисельні значення з 256-бітного вектору цілих чисел b у 256-бітну незгруповану область памʼяті, на яку вказує a.

- _mm256_set1_epi8 -- ініціалізує 256-бітний вектор скалярним цілочисельним значенням (8/16/32/64-бітним), вказаним у параметрі a, розмножуючи його на всі елементи вектора.

- _mm256_cmpeq_epi8 -- виконує SIMD-порівняння на рівність упакованих байтів, слів, даблвордів або квадвордів у вхідних векторах s1 та s2. Якщо пара елементів рівна — відповідний елемент у векторі результату встановлюється в усі 1; якщо не рівна — у 0.

- _mm256_movemask_epi8 -- витягує найстарший біт (MSB) кожного з 32 байтів у векторі a та упаковує їх у 32-бітне ціле число.

## Огляд коду

Так як в оригінальному коді стрічки дуже часто траплявся memcpy його варто було переписати використовуючи інструкції AVX2.

```cpp
inline void avx2_memcpy(const char* src, char* dst, size_t size) {
    size_t i = 0;
    for (; i + 32 <= size; i += 32) {
        __m256i block = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(src + i));
        _mm256_storeu_si256(reinterpret_cast<__m256i*>(dst + i), block);
    }
    for (; i < size; ++i) {
        dst[i] = src[i];
    }
}
```

Також замість використання memset були використані інструкції SIMD зазначені вище:

```cpp
void my_str_avx::resize(size_t new_size, char new_char) {
    if (new_size > size_m) {
        if (new_size > capacity_m) {
            reserve(new_size * 2);
        }
        char* dst = data_m + size_m;
        size_t fill_size = new_size - size_m;
        size_t i = 0;
        __m256i fill_value = _mm256_set1_epi8(static_cast<char>(new_char));
        for (; i + 32 <= fill_size; i += 32) {
            _mm256_storeu_si256(reinterpret_cast<__m256i*>(dst + i), fill_value);
        }
        for (; i < fill_size; ++i) {
            dst[i] = new_char;
        }
    }
    size_m = new_size;
    data_m[size_m] = '\0';
}
```

```cpp
size_t my_str_avx::find(const char* cstr, size_t idx) const {
    if (cstr == nullptr) {
        throw std::logic_error("Null pointer passed to find()");
    }
    if (idx > size_m) {
        throw std::out_of_range("my_str_avx::find");
    }
    size_t str_len = std::strlen(cstr);
    if (str_len == 0) {
        return idx;
    }
    if (str_len > size_m - idx) {
        return not_found;
    }
    
    const char* src = data_m;
    char target = cstr[0];
    __m256i target_vec = _mm256_set1_epi8(target);
    size_t i = idx;

    for (; i + 32 <= size_m; i += 32) {
        __m256i data_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(src + i));
        __m256i cmp = _mm256_cmpeq_epi8(data_vec, target_vec);
        int mask = _mm256_movemask_epi8(cmp);

        while (mask != 0) {
            int offset = __builtin_ctz(mask);
            size_t candidate = i + offset;

            if (candidate + str_len <= size_m &&
                // Використовуємо memcmp для швидкодії. Інший варіант писати свій аналог що буде повільнішим
                std::memcmp(src + candidate, cstr, str_len) == 0) {
                return candidate;
            }

            mask &= (mask - 1);
        }
    }

    for (; i <= size_m - str_len; ++i) {
        if (src[i] == target &&
            // Використовуємо memcmp для швидкодії. Інший варіант писати свій аналог що буде повільнішим
            std::memcmp(src + i, cstr, str_len) == 0) {
            return i;
        }
    }

    return not_found;
}
```


## Аналіз швидкодії

1. Копіювання

Ось порівняння швидкості запуску функцій копіювання для обох варіантів стрічки:

| Size (chars) | my_str_t avg time (μs) | my_str_avx avg time (μs) |
|--------------|------------------------|---------------------------|
| 16 | 0 | 0 |
| 32 | 0 | 0 |
| 64 | 0 | 0 |
| 128 | 0 | 0 |
| 256 | 0 | 0 |
| 512 | 0 | 0 |
| 1024 | 0 | 0 |
| 2048 | 0 | 0 |
| 4096 | 0 | 0 |
| 10000 | 1 | 1 |
| 1000000 | 457 | 516 |
| 10000000 | 4675 | 4871 |
| 100000000 | 33382 | 36792 |

Як видно з таблиці, при копіюванні стрічок малого розміру (до 10 000 символів) різниця в часі між реалізаціями фактично відсутня — обидві працюють практично миттєво. Однак із ростом обсягу даних стає помітним, що звичайна реалізація my_str_t копіює великі стрічки швидше за SIMD-версію my_str_avx. Зокрема, при розмірі 100 мільйонів символів стандартна версія завершує копіювання на понад 3 мс швидше. Це свідчить про те, що в задачі копіювання великих обсягів даних традиційні інструменти C++ (зокрема memcpy) залишаються надзвичайно ефективними, й SIMD-інструкції, ймовірно, не компенсують своїх накладних витрат на ініціалізацію та вирівнювання.

2. Функція shrink_to_fit

Ось порівняння швидкості запуску функцій shrink_to_fit для обох варіантів стрічки:

| Size (chars) | shrink memcpy (μs) | shrink SIMD (μs) |
|--------------|--------------------|------------------|
| 16 | 0 | 0 |
| 32 | 0 | 0 |
| 64 | 0 | 0 |
| 128 | 0 | 0 |
| 256 | 0 | 0 |
| 512 | 0 | 0 |
| 1024 | 0 | 0 |
| 2048 | 0 | 0 |
| 4096 | 1 | 2 |
| 10000 | 3 | 3 |
| 1000000 | 602 | 589 |
| 10000000 | 7020 | 7170 |

З результатів видно, що для малих розмірів стрічки (до кількох тисяч символів) виконання функції shrink_to_fit практично миттєве в обох реалізаціях. Починаючи з розміру у мільйон символів, спостерігається незначна перевага SIMD-реалізації: вона показує трохи кращі результати, зокрема на 13 мкс швидше при 1 000 000 символів. Проте при ще більших обсягах (10 000 000 символів) ця перевага втрачається — SIMD-реалізація стає навіть повільнішою. Це свідчить про те, що при виконанні shrink_to_fit швидкодія SIMD залежить від конкретного обсягу даних і не є стабільно кращою, що, ймовірно, пов’язано з характером алокацій та кешування в системі.

3. Функція insert

Ось порівняння швидкості запуску функцій insert для обох варіантів стрічки:

| Size (chars) | insert memcpy/memmove (μs) | insert SIMD (μs) |
|--------------|----------------------------|-----------------|
| 16 | 0 | 0 |
| 32 | 0 | 0 |
| 64 | 0 | 0 |
| 128 | 0 | 0 |
| 256 | 0 | 0 |
| 512 | 0 | 0 |
| 1024 | 0 | 0 |
| 2048 | 0 | 0 |
| 4096 | 1 | 1 |
| 10000 | 2 | 2 |
| 1000000 | 587 | 598 |

Як можемо бачити, обидві реалізації функції `insert` демонструють майже ідентичну продуктивність для невеликих розмірів стрічки — до 10 000 символів час виконання дорівнює або близький до нуля. Починаючи з розміру 1 000 000 символів, спостерігається мінімальне зростання часу, але й тут різниця між звичайною та SIMD-реалізацією становить лише близько 11 мкс, що в межах похибки вимірювань. Це свідчить про те, що SIMD не дає помітного прискорення у випадку вставки, ймовірно через складність переносу даних у памʼяті, де швидкість визначається не лише копіюванням, а й зміщенням елементів.

4. Функція reserve

Ось порівняння швидкості запуску функцій reserve для обох варіантів стрічки:

| Size (chars) | reserve memcpy (μs) | reserve SIMD (μs) |
|--------------|---------------------|-------------------|
| 16 | 0 | 0 |
| 32 | 0 | 0 |
| 64 | 0 | 0 |
| 128 | 0 | 0 |
| 256 | 0 | 0 |
| 512 | 0 | 0 |
| 1024 | 0 | 0 |
| 2048 | 1 | 1 |
| 4096 | 1 | 1 |
| 10000 | 3 | 3 |
| 1000000 | 792 | 848 |
| 10000000 | 7614 | 7490 |

У випадку функції reserve обидві реалізації — як звичайна, так і SIMD — демонструють однакову продуктивність для малих обʼємів даних (до 10 000 символів), із часом виконання від 0 до 3 мкс. При роботі з великими обʼємами (1 000 000 та 10 000 000 символів) спостерігається очікуване зростання часу, однак різниця між реалізаціями залишається незначною — на рівні 50–150 мкс. Цікаво, що SIMD-варіант дещо повільніший на 1 мільйоні символів, але випереджає звичайний варіант на 10 мільйонах, що може свідчити про ефективнішу роботу AVX2 при досягненні певного порогу обʼєму памʼяті. Проте загалом переваги SIMD у цьому випадку не є значущими.

## Висновки
Отже, згідно з проведеними тестами (продемонстрованими раніше та іншимими), SIMD-реалізація my_str_avx демонструє перевагу лише у вибіркових сценаріях — зокрема, у функції find, де вона значно випереджає звичайну реалізацію my_str_t (до 10–20 разів швидше при великих обʼємах даних). Водночас при операціях insert, erase, resize та reserve класична реалізація здебільшого показує кращу або подібну продуктивність, переважаючи SIMD у більшості випадків на десятки або навіть сотні мікросекунд. Особливо це помітно для resize, де різниця може сягати до 1056 мкс, та insert, де перевага класичної реалізації зростає з розміром буфера. Таким чином, хоча SIMD може дати значне прискорення в задачах пошуку (find), його використання в інших операціях може бути недоцільним через складність реалізації та слабке масштабування. Найефективнішим виглядає гібридний підхід, де SIMD використовується лише для обчислювально інтенсивних функцій.